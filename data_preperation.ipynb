{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a virtual environment for the project (Windows)\n",
    "```bash\n",
    "# Create a virtual environment\n",
    "python -m venv .venv\n",
    "\n",
    "# Activate the virtual environment\n",
    ".\\.venv\\Scripts\\Activate.ps1\n",
    "```\n",
    "Ensure that the kernel selected is the one from the virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs all dependencies from requirements.txt\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This cell will attempt to create a csv file containing mappings of the image\n",
    "file name along with its numerical label.\n",
    "'''\n",
    "import os  # For file path operations\n",
    "import pandas as pd  # For data manipulation\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataset_path = \"./frames/\"\n",
    "\n",
    "# Define the categories\n",
    "categories = [\"norm\", \"weap\"]  # 0 = norm, 1 = weap\n",
    "\n",
    "# Loop through the categories and the train/test folders\n",
    "for category in categories:\n",
    "    for folder in [\"train\", \"test\"]:\n",
    "        # Initialize an empty list to store the data\n",
    "        data = []\n",
    "\n",
    "        folder_path = os.path.join(dataset_path, folder, category)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            # Append the filename and the label to the data list\n",
    "            label = 1 if category == \"weap\" else 0\n",
    "            data.append((os.path.join(category, filename), label))\n",
    "\n",
    "        # Create a Pandas DataFrame from the data list\n",
    "        df = pd.DataFrame(data, columns=[\"filename\", \"label\"])\n",
    "\n",
    "        # Save the DataFrame to a CSV file\n",
    "        df.to_csv(f\"{folder}_annotations.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # For building the models\n",
    "\n",
    "# Environment Information\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"GPU Devices Detected: {torch.cuda.device_count()}\")\n",
    "print(f\"1st GPU Device Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of Data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io import read_image\n",
    "\n",
    "# Class for Custom Image Dataset\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    # https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = str(self.img_labels.iloc[idx, 0])\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms.v2 as transforms\n",
    "from torchvision.transforms.autoaugment import AutoAugmentPolicy\n",
    "\n",
    "# Define the transforms\n",
    "transform_baseline = transforms.Compose([\n",
    "    # https://pytorch.org/vision/stable/transforms.html#v2-api-reference-recommended\n",
    "    transforms.Grayscale(num_output_channels=1),  # Convert to grayscale\n",
    "    transforms.Resize((512, 512)),  # Resize to 512x512\n",
    "])\n",
    "\n",
    "size = (512, 512)\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform_basicaugmentation = transforms.Compose([\n",
    "    transforms.Resize(size),            # Resize to 512x512\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    # transforms.RandomCrop(size),        # Randomly crop the image to 512x512\n",
    "    transforms.ToDtype(torch.float),        # Convert to float\n",
    "    transforms.Normalize(mean, std),    # Normalize the image\n",
    "    transforms.RandomErasing()          # Randomly erase parts of the image\n",
    "])\n",
    "\n",
    "transform_autoaugmentation = transforms.Compose([\n",
    "    transforms.Resize(size),            # Resize to 512x512\n",
    "    transforms.RandomHorizontalFlip(),  # Randomly flip the image horizontally\n",
    "    # transforms.RandomCrop(size),        # Randomly crop the image to 512x512\n",
    "    transforms.AutoAugment(AutoAugmentPolicy.CIFAR10),  # Apply AutoAugment\n",
    "    # transforms.ToDtype(torch.float),        # Convert to float\n",
    "    # transforms.Normalize(mean, std),    # Normalize the image\n",
    "    transforms.RandomErasing()          # Randomly erase parts of the image\n",
    "])\n",
    "\n",
    "transform = transform_autoaugmentation\n",
    "\n",
    "# Apply the transforms to the dataset\n",
    "training_data = CustomImageDataset(\n",
    "    \"train_annotations.csv\", os.path.join(dataset_path, \"train\"), transform=transform, target_transform=None)\n",
    "test_data = CustomImageDataset(\n",
    "    \"test_annotations.csv\", os.path.join(dataset_path, \"train\"), transform=transform, target_transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt  # For visualization\n",
    "\n",
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(torch.permute(img, [1,2,0]))\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
